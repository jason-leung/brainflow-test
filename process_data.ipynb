{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0fcdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f04187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, pyxdf, json, yaml\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from mne.time_frequency import psd_welch, tfr_morlet, tfr_multitaper\n",
    "# from multitaper_spectrogram_python import multitaper_spectrogram\n",
    "from mne.decoding import Scaler, Vectorizer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, HalvingGridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0ee15",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99db2e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': 'P00J', 'session': 1, 'task': 'MI-hands', 'eeg_stream_type': 'EXG', 'markers_stream_type': 'Marker', 'default_ch_names': ['Fz', 'FC1', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2', 'P3', 'Pz', 'P4', 'PO3', 'PO4', 'O1', 'Oz', 'O2'], 'montage_file': 'openbci_montage.elc', 'event_dict': {'rest': 0, 'MI/hands': 1}, 'rest_duration': 5, 'task_duration': 5, 'tmin': 0, 'tmax': 5, 'plotGraphs': False, 'scalings': {'eeg': 0.0002}, 'plot_duration': 10, 'bp_l_freq': 1.0, 'bp_h_freq': 40.0, 'performICA': False, 'features': 'tfr', 'tfr_type': 'morlet', 'baseline': (0.0, 0.1), 'vmin': -1.0, 'vmax': 1.0}\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config_MI-hands.yaml'\n",
    "\n",
    "with open(config_file) as f:\n",
    "    config = yaml.load(f.read(), Loader=yaml.Loader)\n",
    "    print(config)\n",
    "    locals().update(config)\n",
    "\n",
    "lslDir = os.path.join(os.path.expanduser('~'), 'Documents\\CurrentStudy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df62ee7",
   "metadata": {},
   "source": [
    "### Find LSL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93040a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-P00J_ses-S001_task-MI-hands_run-001_eeg.xdf\n",
      "sub-P00J_ses-S001_task-MI-hands_run-002_eeg.xdf\n",
      "sub-P00J_ses-S001_task-MI-hands_run-003_eeg.xdf\n",
      "sub-P00J_ses-S001_task-MI-hands_run-004_eeg.xdf\n",
      "sub-P00J_ses-S001_task-MI-hands_run-005_eeg.xdf\n"
     ]
    }
   ],
   "source": [
    "# Find files\n",
    "xdf_files = []\n",
    "hasSubject = subject!=''\n",
    "hasSession = session!=''\n",
    "hasTask = task!=''\n",
    "for root, dir, files in os.walk(lslDir):\n",
    "    for file in files:\n",
    "        validFile = True\n",
    "        if hasSubject:\n",
    "            validFile = validFile and (('sub-'+subject) in file)\n",
    "        if hasSession:\n",
    "            validFile = validFile and (('ses-S' + str(session).zfill(3)) in file)\n",
    "        if hasTask:\n",
    "            validFile = validFile and (('task-' + task) in file)\n",
    "        validFile = validFile and file.endswith('.xdf')\n",
    "        if validFile:\n",
    "            print(file)\n",
    "            matchingFile = os.path.join(root, file)\n",
    "            xdf_files.append(matchingFile)\n",
    "\n",
    "if len(xdf_files) == 0:\n",
    "    print('No files found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082bb234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing streams\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-001_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-001_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-002_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-002_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-003_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-003_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-004_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-004_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-005_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-005_eeg.xdf\n"
     ]
    }
   ],
   "source": [
    "# Parse streams\n",
    "eeg_stream, marker_stream = [], []\n",
    "\n",
    "print('Parsing streams')\n",
    "for xdf_file in xdf_files:\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)\n",
    "    for i in range(len(streams)):\n",
    "        if streams[i]['info']['type'][0] == eeg_stream_type:\n",
    "            print(\"Found %s stream in %s\" % (eeg_stream_type, os.path.basename(xdf_file)))\n",
    "            eeg_stream.append(streams[i])\n",
    "        elif streams[i]['info']['type'][0] == markers_stream_type:\n",
    "            print(\"Found %s stream in %s\" % (markers_stream_type, os.path.basename(xdf_file)))\n",
    "            marker_stream.append(streams[i])\n",
    "del streams, header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af60e1",
   "metadata": {},
   "source": [
    "### Extract EEG and Marker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "569b6f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EEG info...\n",
      "Channels:  ['Fz', 'FC1', 'FC2', 'C3', 'Cz', 'C4', 'CP1', 'CP2', 'P3', 'Pz', 'P4', 'PO3', 'PO4', 'O1', 'Oz', 'O2']\n",
      "Sampling frequency:  125.0\n"
     ]
    }
   ],
   "source": [
    "# Extract EEG Info\n",
    "print(\"Extracting EEG info...\")\n",
    "\n",
    "ch_names = []\n",
    "if eeg_stream[0]['info']['desc'][0]:\n",
    "    print(\"EEG channel names found\")\n",
    "    for i in range(len(eeg_stream[0]['info']['desc'][0]['channels'][0]['channel'])):\n",
    "        ch_names.append(eeg_stream[0]['info']['desc'][0]['channels'][0]['channel'][i]['label'][0])\n",
    "else:\n",
    "    ch_names = default_ch_names\n",
    "print('Channels: ', ch_names)\n",
    "\n",
    "sfreq = float(eeg_stream[0]['info']['nominal_srate'][0])\n",
    "print('Sampling frequency: ', sfreq)\n",
    "\n",
    "# Create MNE info object\n",
    "eeg_info = mne.create_info(ch_names, sfreq, ch_types='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f764ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Montage\n",
    "montage = mne.channels.read_custom_montage(montage_file)\n",
    "# montage.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8048953f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 21034)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=21034\n",
      "    Range : 0 ... 21033 =      0.000 ...   168.264 secs\n",
      "Ready.\n",
      "(16, 20911)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=20911\n",
      "    Range : 0 ... 20910 =      0.000 ...   167.280 secs\n",
      "Ready.\n",
      "(16, 20765)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=20765\n",
      "    Range : 0 ... 20764 =      0.000 ...   166.112 secs\n",
      "Ready.\n",
      "(16, 20644)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=20644\n",
      "    Range : 0 ... 20643 =      0.000 ...   165.144 secs\n",
      "Ready.\n",
      "(16, 20760)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=20760\n",
      "    Range : 0 ... 20759 =      0.000 ...   166.072 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# Get all EEG data\n",
    "eeg_raw_list = []\n",
    "\n",
    "for n in range(len(eeg_stream)):\n",
    "    # Create MNE Raw object\n",
    "    eeg_data = np.transpose(eeg_stream[n]['time_series'])\n",
    "    eeg_data = eeg_data / 1e6\n",
    "    print(eeg_data.shape)\n",
    "    eeg_raw = mne.io.RawArray(eeg_data, eeg_info)\n",
    "    \n",
    "    # Set montage\n",
    "    eeg_raw = eeg_raw.set_montage(montage)\n",
    "\n",
    "    # Add annotations\n",
    "    onset, duration, description = [], [], []\n",
    "    current_target = -1\n",
    "    current_flash = -1\n",
    "    for i in range(len(marker_stream[n]['time_series'])):\n",
    "        if 'MI' in task:\n",
    "            if ('rest' in marker_stream[n]['time_series'][i][0]):\n",
    "                onset.append(marker_stream[n]['time_stamps'][i] - eeg_stream[n]['time_stamps'][0])\n",
    "                duration.append(rest_duration)\n",
    "                description.append(marker_stream[n]['time_series'][i][0])\n",
    "            elif ('task' in marker_stream[n]['time_series'][i][0]):\n",
    "                onset.append(marker_stream[n]['time_stamps'][i] - eeg_stream[n]['time_stamps'][0])\n",
    "                duration.append(task_duration)\n",
    "                description.append(marker_stream[n]['time_series'][i][0].replace('task_', '').replace('-','/'))\n",
    "        elif 'P300' in task:\n",
    "            if('target' in marker_stream[n]['time_series'][i][0]):\n",
    "                current_target = json.loads(marker_stream[n]['time_series'][i][0])['target']\n",
    "            elif('flash' in marker_stream[n]['time_series'][i][0]):\n",
    "                current_flash = json.loads(marker_stream[n]['time_series'][i][0])['flash']\n",
    "                onset.append(marker_stream[n]['time_stamps'][i] - eeg_stream[n]['time_stamps'][0])\n",
    "                duration.append(task_duration)\n",
    "                description.append(\"target\" if current_flash == current_target else \"nontarget\")\n",
    "    annotations = mne.Annotations(onset, duration, description)\n",
    "    eeg_raw = eeg_raw.set_annotations(annotations)\n",
    "    \n",
    "    # Create list of raw objects\n",
    "    eeg_raw_list.append(eeg_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce8688d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>19 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>16 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>62.50 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:13:52 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawArray | 16 x 104114 (832.9 s), ~12.7 MB, data loaded>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate raw objects\n",
    "raw = mne.concatenate_raws(eeg_raw_list)\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e81434",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91852a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "# Common average reference\n",
    "raw_orig = raw.copy()\n",
    "raw = raw.set_eeg_reference('average', projection=False)\n",
    "\n",
    "if plotGraphs:\n",
    "    fig = raw_orig.plot(title='Before Re-referencing', n_channels=16, scalings=scalings)\n",
    "    fig = raw.plot(title='After Re-referencing', n_channels=16, scalings=scalings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0930ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 5 contiguous segments\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 413 samples (3.304 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bandpass filter data\n",
    "raw_orig = raw.copy()\n",
    "raw = raw.filter(l_freq=bp_l_freq, h_freq=bp_h_freq)\n",
    "\n",
    "if plotGraphs:\n",
    "    fig = raw_orig.plot(title='Before Filtering', scalings=scalings, duration=plot_duration)\n",
    "    fig = raw.plot(title='After Filtering', scalings=scalings, duration=plot_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b855a6",
   "metadata": {},
   "source": [
    "### ICA Artifact Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b190f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if performICA:\n",
    "    print('Performing ICA artifact removal...')\n",
    "    raw_orig = raw.copy()\n",
    "\n",
    "    # filter data to remove slow drifts\n",
    "    raw_filt = raw.copy()\n",
    "    raw_filt.filter(l_freq=1., h_freq=None)\n",
    "\n",
    "    # ICA decomposition\n",
    "    ica = mne.preprocessing.ICA(n_components=16, method='fastica', max_iter=200, random_state=42, verbose=True)\n",
    "    ica = ica.fit(raw_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1828eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ICA sources\n",
    "if performICA and plotGraphs:\n",
    "    fig = ica.plot_sources(raw_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb69e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select source that corresponds to artifact and remove it\n",
    "if performICA:\n",
    "    ica.exclude = [0]\n",
    "    # ica.exclude = [2]\n",
    "    print('ICA sources to exclude: ', ica.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86f41cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if performICA:\n",
    "    ica.apply(raw)\n",
    "    if plotGraphs:\n",
    "        fig = raw_orig.plot(title='Before ICA', scalings=scalings, duration=plot_duration)\n",
    "        fig = raw.plot(title='After ICA', scalings=scalings, duration=plot_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca8d881",
   "metadata": {},
   "source": [
    "### Epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5c88f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['MI/hands', 'rest']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 100 events and 626 original time points ...\n",
      "0 bad epochs dropped\n",
      "<Epochs |  100 events (all good), 0 - 5 sec, baseline off, ~7.7 MB, data loaded,\n",
      " 'MI/hands': 50\n",
      " 'rest': 50>\n"
     ]
    }
   ],
   "source": [
    "# Epoch data\n",
    "events, event_id = mne.events_from_annotations(raw, event_id=event_dict)\n",
    "epoch = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, picks='eeg', preload=True)\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e4a0e",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "806fe2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "y = epoch.events[:,-1] - min(epoch.events[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "974006a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "# Time-Domain Features\n",
    "if features == 'time':\n",
    "    scaler = Scaler(epoch.info)\n",
    "    X = scaler.fit_transform(epoch.get_data())\n",
    "    \n",
    "    if ('P300' in task) and plotGraphs:\n",
    "        fig = epoch['target'].average().plot_joint(times=[-0.2, 0., 0.3, 0.7], ts_args=dict(ylim=dict(eeg=[-10, 10])))\n",
    "        fig = epoch['nontarget'].average().plot_joint(times=[-0.2, 0., 0.3, 0.7], ts_args=dict(ylim=dict(eeg=[-10, 10])))\n",
    "#         fig = epoch['target'].average().plot_joint(times=[-0.2, 0., 0.3, 0.7], picks=['Fz','Cz','P3','Pz','P4','PO3','PO4','Oz'], ts_args=dict(ylim=dict(eeg=[-10, 10])))\n",
    "#         fig = epoch['nontarget'].average().plot_joint(times=[-0.2, 0., 0.3, 0.7], picks=['Fz','Cz','P3','Pz','P4','PO3','PO4','Oz'], ts_args=dict(ylim=dict(eeg=[-10, 10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1db58950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Frequency-Domain Features\n",
    "if features == 'psd':\n",
    "    psds, freqs = psd_welch(epoch, average='mean', fmin=bp_l_freq, fmax=bp_h_freq, n_jobs=-1)\n",
    "    X = 10 * np.log10(psds)\n",
    "#     X = psds / np.sum(psds, axis=-1, keepdims=True)\n",
    "    \n",
    "    if ('MI' in task) and plotGraphs:\n",
    "        sel_chs = [2, 3, 4, 5, 6, 7, 14, 15]\n",
    "        psd_means_class_0 = np.transpose(np.mean(X[y==0], axis=0))\n",
    "        psd_means_class_1 = np.transpose(np.mean(X[y==1], axis=0))\n",
    "        psd_means_class_0 = psd_means_class_0[:,sel_chs]\n",
    "        psd_means_class_1 = psd_means_class_1[:,sel_chs]\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        for i in range(len(sel_chs)):\n",
    "            line = ax.plot(freqs, psd_means_class_0[:,i], ':', label=ch_names[sel_chs[i]] + ' Rest')\n",
    "            ax.plot(freqs, psd_means_class_1[:,i], '-', label=ch_names[sel_chs[i]] + ' MI-hands', color=line[0].get_color())\n",
    "        ax.set(title='Welch PSD', xlabel='Frequency (Hz)', ylabel='Power Spectral Density (dB)')\n",
    "        ax.set_ylim(bottom=-135, top=-85)\n",
    "        ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d054eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFR freqs:  [ 6.          7.71912254  9.93080879 12.77618833 16.43682721 21.1463139\n",
      " 27.2051647  35.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "(100, 16, 8, 626)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  16 out of  16 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Time-frequency features\n",
    "if features =='tfr':\n",
    "    # Parameters\n",
    "    freqs = np.logspace(*np.log10([6, 35]), num=8)\n",
    "#     freqs = np.linspace(2, 40, 20)\n",
    "    print('TFR freqs: ', freqs)\n",
    "    n_cycles = freqs / 2.\n",
    "    time_bandwidth = 4.0 # param for multitaper\n",
    "    \n",
    "    # Compute TFR Power\n",
    "    if tfr_type == 'morlet':\n",
    "        power = tfr_morlet(epoch, freqs, n_cycles=n_cycles, use_fft=False, return_itc=False, average=False, n_jobs=-1)\n",
    "    elif tfr_type == 'multitaper':\n",
    "        power = tfr_multitaper(epoch, freqs, n_cycles=n_cycles, time_bandwidth=time_bandwidth, use_fft=False, return_itc=False, average=False, n_jobs=-1)\n",
    "    print(power.data.shape)\n",
    "    X = power.data\n",
    "    \n",
    "    if ('MI' in task) and plotGraphs:\n",
    "        fig = power['rest'].average().plot_topo(baseline=baseline, mode='percent', cmap='jet', tmin=tmin, tmax=tmax, vmin=vmin, vmax=vmax, title='Average power (Rest)')\n",
    "        fig = power['MI/hands'].average().plot_topo(baseline=baseline, mode='percent', cmap='jet', tmin=tmin, tmax=tmax, vmin=vmin, vmax=vmax, title='Average power (MI-hands)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76871933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.close('all')\n",
    "# baseline = (0., 0.1)\n",
    "# vmin, vmax = -1, 1\n",
    "# fig = power['rest'].average().plot_topo(baseline=baseline, mode='percent', tmin=tmin, tmax=tmax, vmin=vmin, vmax=vmax, title='Average power (Rest)')\n",
    "# fig = power['MI/hands'].average().plot_topo(baseline=baseline, mode='percent', tmin=tmin, tmax=tmax, vmin=vmin, vmax=vmax, title='Average power (MI-hands)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92b6ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select Channels\n",
    "# print('Selecting channels from data...')\n",
    "# print('Original X.shape: ', X.shape)\n",
    "# X = X[:,2:, :]\n",
    "# print('X.shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4adf9cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing features to 2D...\n",
      "Original X.shape:  (100, 16, 8, 626)\n",
      "X.shape:  (100, 80128)\n",
      "y.shape:  (100,)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize features\n",
    "if len(X.shape) > 2:\n",
    "    print('Vectorizing features to 2D...')\n",
    "    print('Original X.shape: ', X.shape)\n",
    "    vec = Vectorizer()\n",
    "    X = vec.fit_transform(X)\n",
    "\n",
    "print('X.shape: ', X.shape)\n",
    "print('y.shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59010a6",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4968dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "# Set up scoring\n",
    "scoring = 'accuracy'\n",
    "scores = {'Classifier': [],\n",
    "          'Score': [],\n",
    "          'Std': []\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47498dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Classifiers\n",
    "classifiers = []\n",
    "\n",
    "# KNN\n",
    "params = {}\n",
    "params['n_neighbors'] = np.arange(2,11,1)\n",
    "params['weights'] = ['uniform', 'distance']\n",
    "clf = HalvingGridSearchCV(KNeighborsClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['KNN', clf, params])\n",
    "\n",
    "# DT\n",
    "params = {}\n",
    "params['criterion'] = ['gini', 'entropy']\n",
    "params['min_samples_split'] = np.arange(2,11,2)\n",
    "clf = HalvingGridSearchCV(DecisionTreeClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['DT', clf, params])\n",
    "\n",
    "# RF\n",
    "params = {}\n",
    "params['criterion'] = ['gini', 'entropy']\n",
    "params['n_estimators'] = (10, 20, 30)\n",
    "params['min_samples_split'] = np.arange(2,11,2)\n",
    "clf = HalvingGridSearchCV(RandomForestClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['RF', clf, params])\n",
    "\n",
    "# LDA\n",
    "params = {}\n",
    "params['solver'] = ['svd']\n",
    "clf = HalvingGridSearchCV(LinearDiscriminantAnalysis(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['LDA', clf, params])\n",
    "\n",
    "# SVM\n",
    "params = {}\n",
    "params['C'] = (1e-4, 1e-2, 1)\n",
    "params['gamma'] = (1e-4, 1e-2, 1, 10)\n",
    "params['kernel'] = ['linear', 'rbf']\n",
    "clf = HalvingGridSearchCV(SVC(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['SVM', clf, params])\n",
    "\n",
    "# SGD\n",
    "params = {}\n",
    "params['loss'] = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "params['penalty'] = ['l2', 'l1', 'elasticnet']\n",
    "params['alpha'] = (1e-4, 1e-2, 1, 10)\n",
    "clf = HalvingGridSearchCV(SGDClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['SGD', clf, params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa4fdb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN...\n",
      "KNN score: 0.66\n",
      "KNN std  : 0.07\n",
      "\n",
      "Training DT...\n",
      "DT score: 0.51\n",
      "DT std  : 0.04\n",
      "\n",
      "Training RF...\n",
      "RF score: 0.51\n",
      "RF std  : 0.04\n",
      "\n",
      "Training LDA...\n",
      "LDA score: 0.48\n",
      "LDA std  : 0.07\n",
      "\n",
      "Training SVM...\n",
      "SVM score: 0.51\n",
      "SVM std  : 0.00\n",
      "\n",
      "Training SGD...\n",
      "SGD score: 0.50\n",
      "SGD std  : 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Classifiers\n",
    "for c in range(len(classifiers)):\n",
    "    clf_name = classifiers[c][0]\n",
    "    clf = classifiers[c][1].fit(X, y)\n",
    "    print(\"Training %s...\" % clf_name)\n",
    "    print('%s score: %2.2f' % (clf_name, clf.best_score_))\n",
    "    print('%s std  : %2.2f' % (clf_name, np.mean(clf.cv_results_['std_test_score'])))\n",
    "    print()\n",
    "    scores['Classifier'].append(clf_name)\n",
    "    scores['Score'].append(clf.best_score_)\n",
    "    scores['Std'].append(np.mean(clf.cv_results_['std_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6522303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.067729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.036331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.038524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.068877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.003627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.001196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Score       Std\n",
       "0        KNN  0.656  0.067729\n",
       "1         DT  0.506  0.036331\n",
       "2         RF  0.508  0.038524\n",
       "3        LDA  0.484  0.068877\n",
       "4        SVM  0.508  0.003627\n",
       "5        SGD  0.500  0.001196"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score summary\n",
    "df = pd.DataFrame(scores)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba6adb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Classifier:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier         KNN\n",
       "Score            0.656\n",
       "Std           0.067729\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Classifier\n",
    "print('Best Classifier:')\n",
    "df.loc[df['Score'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4d918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
