{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0fcdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f04187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, pyxdf, json\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from mne.time_frequency import psd_welch, tfr_morlet, tfr_multitaper\n",
    "# from multitaper_spectrogram_python import multitaper_spectrogram\n",
    "from mne.decoding import Scaler, Vectorizer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, HalvingGridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0ee15",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd8160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "subject = 'P00J'\n",
    "session = 1\n",
    "task = 'MI-hands'\n",
    "# task = 'P300_4x4_gface'\n",
    "lslDir = os.path.join(os.path.expanduser('~'), 'Documents\\CurrentStudy')\n",
    "\n",
    "# LSL Stream\n",
    "eeg_stream_type = 'EXG'\n",
    "markers_stream_type = 'Marker'\n",
    "\n",
    "# Events\n",
    "if task == 'MI-hands':\n",
    "    event_dict = {'rest': 0, 'MI/hands': 1}\n",
    "    rest_duration = 5\n",
    "    task_duration = 5\n",
    "    tmin = 0\n",
    "    tmax = 5\n",
    "elif 'P300' in task:\n",
    "    event_dict = {'nontarget': 0, 'target': 1}\n",
    "    task_duration = 1\n",
    "    tmin = 0\n",
    "    tmax = 1\n",
    "\n",
    "# Plot\n",
    "plotGraphs = False\n",
    "scalings = dict(eeg=200e-6)\n",
    "plot_duration = 10\n",
    "\n",
    "# Bandpass filter\n",
    "bp_l_freq = 0.1\n",
    "bp_h_freq = 40.\n",
    "\n",
    "# Features\n",
    "ft_chs = ['C3', 'C4']\n",
    "# features = 'time'\n",
    "# features = 'psd'\n",
    "features = 'tfr'\n",
    "tfr_type = 'morlet'\n",
    "baseline = (0., 0.1)\n",
    "vmin, vmax = -1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e14168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sub-folder for data\n",
    "fif_dir = os.path.join('fif')\n",
    "if not os.path.exists(fif_dir):\n",
    "    os.makedirs(fif_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df62ee7",
   "metadata": {},
   "source": [
    "### Find LSL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93040a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-P00J_ses-S001_task-MI-hands_run-001_eeg.xdf\n",
      "sub-P00J_ses-S001_task-MI-hands_run-002_eeg.xdf\n",
      "sub-P00J_ses-S001_task-MI-hands_run-003_eeg.xdf\n",
      "sub-P00J_ses-S001_task-MI-hands_run-004_eeg.xdf\n",
      "sub-P00J_ses-S001_task-MI-hands_run-005_eeg.xdf\n"
     ]
    }
   ],
   "source": [
    "# Find files\n",
    "xdf_files = []\n",
    "hasSubject = subject!=''\n",
    "hasSession = session!=''\n",
    "hasTask = task!=''\n",
    "for root, dir, files in os.walk(lslDir):\n",
    "    for file in files:\n",
    "        validFile = True\n",
    "        if hasSubject:\n",
    "            validFile = validFile and (('sub-'+subject) in file)\n",
    "        if hasSession:\n",
    "            validFile = validFile and (('ses-S' + str(session).zfill(3)) in file)\n",
    "        if hasTask:\n",
    "            validFile = validFile and (('task-' + task) in file)\n",
    "        validFile = validFile and file.endswith('.xdf')\n",
    "        if validFile:\n",
    "            print(file)\n",
    "            matchingFile = os.path.join(root, file)\n",
    "            xdf_files.append(matchingFile)\n",
    "\n",
    "if len(xdf_files) == 0:\n",
    "    print('No files found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082bb234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing streams\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-001_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-001_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-002_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-002_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-003_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-003_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-004_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-004_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-MI-hands_run-005_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-MI-hands_run-005_eeg.xdf\n"
     ]
    }
   ],
   "source": [
    "# Parse streams\n",
    "eeg_stream, marker_stream = [], []\n",
    "\n",
    "print('Parsing streams')\n",
    "for xdf_file in xdf_files:\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)\n",
    "    for i in range(len(streams)):\n",
    "        if streams[i]['info']['type'][0] == eeg_stream_type:\n",
    "            print(\"Found %s stream in %s\" % (eeg_stream_type, os.path.basename(xdf_file)))\n",
    "            eeg_stream.append(streams[i])\n",
    "        elif streams[i]['info']['type'][0] == markers_stream_type:\n",
    "            print(\"Found %s stream in %s\" % (markers_stream_type, os.path.basename(xdf_file)))\n",
    "            marker_stream.append(streams[i])\n",
    "del streams, header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af60e1",
   "metadata": {},
   "source": [
    "### Extract EEG and Marker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569b6f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EEG info\n",
      "EEG channel names not found... setting default\n",
      "Channels:  ['FP1', 'FP2', 'C3', 'C4', 'P7', 'P8', 'O1', 'O2', 'F7', 'F8', 'F3', 'F4', 'T7', 'T8', 'P3', 'P4']\n",
      "Sampling frequency:  125.0\n"
     ]
    }
   ],
   "source": [
    "# Extract EEG Info\n",
    "print(\"Extracting EEG info\")\n",
    "\n",
    "ch_names = []\n",
    "if eeg_stream[0]['info']['desc'][0]:\n",
    "    print(\"EEG channel names found\")\n",
    "    for i in range(len(eeg_stream[0]['info']['desc'][0]['channels'][0]['channel'])):\n",
    "        ch_names.append(eeg_stream[0]['info']['desc'][0]['channels'][0]['channel'][i]['label'][0])\n",
    "else:\n",
    "    print(\"EEG channel names not found... setting default\")\n",
    "    ch_names = ['FP1', 'FP2', 'C3', 'C4', 'P7', 'P8', 'O1', 'O2', 'F7', 'F8', 'F3', 'F4', 'T7', 'T8', 'P3', 'P4']\n",
    "print('Channels: ', ch_names)\n",
    "\n",
    "sfreq = float(eeg_stream[0]['info']['nominal_srate'][0])\n",
    "print('Sampling frequency: ', sfreq)\n",
    "\n",
    "# Create MNE info object\n",
    "eeg_info = mne.create_info(ch_names, sfreq, ch_types='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f764ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Montage\n",
    "montage = mne.channels.read_custom_montage('openbci_montage.elc')\n",
    "# montage.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8048953f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 22024)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=22024\n",
      "    Range : 0 ... 22023 =      0.000 ...   176.184 secs\n",
      "Ready.\n",
      "(16, 21138)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=21138\n",
      "    Range : 0 ... 21137 =      0.000 ...   169.096 secs\n",
      "Ready.\n",
      "(16, 20893)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=20893\n",
      "    Range : 0 ... 20892 =      0.000 ...   167.136 secs\n",
      "Ready.\n",
      "(16, 20762)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=20762\n",
      "    Range : 0 ... 20761 =      0.000 ...   166.088 secs\n",
      "Ready.\n",
      "(16, 20883)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=20883\n",
      "    Range : 0 ... 20882 =      0.000 ...   167.056 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# Get all EEG data\n",
    "eeg_raw_list = []\n",
    "\n",
    "for n in range(len(eeg_stream)):\n",
    "    # Create MNE Raw object\n",
    "    eeg_data = np.transpose(eeg_stream[n]['time_series'])\n",
    "    eeg_data = eeg_data / 1e6\n",
    "    print(eeg_data.shape)\n",
    "    eeg_raw = mne.io.RawArray(eeg_data, eeg_info)\n",
    "    \n",
    "#     # Set FP1 and FP2 as EOG channels\n",
    "#     eeg_raw = eeg_raw.set_channel_types({'FP1': 'eog', 'FP2': 'eog'})\n",
    "#     eeg_raw.pick_types(eeg=True, eog=True)\n",
    "    \n",
    "    # Set montage\n",
    "    eeg_raw = eeg_raw.set_montage(montage)\n",
    "\n",
    "    # Add annotations\n",
    "    onset, duration, description = [], [], []\n",
    "    current_target = -1\n",
    "    current_flash = -1\n",
    "    for i in range(len(marker_stream[n]['time_series'])):\n",
    "        if 'MI' in task:\n",
    "            if ('rest' in marker_stream[n]['time_series'][i][0]):\n",
    "                onset.append(marker_stream[n]['time_stamps'][i] - eeg_stream[n]['time_stamps'][0])\n",
    "                duration.append(rest_duration)\n",
    "                description.append(marker_stream[n]['time_series'][i][0])\n",
    "            elif ('task' in marker_stream[n]['time_series'][i][0]):\n",
    "                onset.append(marker_stream[n]['time_stamps'][i] - eeg_stream[n]['time_stamps'][0])\n",
    "                duration.append(task_duration)\n",
    "                description.append(marker_stream[n]['time_series'][i][0].replace('task_', '').replace('-','/'))\n",
    "        elif 'P300' in task:\n",
    "            if('target' in marker_stream[n]['time_series'][i][0]):\n",
    "                current_target = json.loads(marker_stream[n]['time_series'][i][0])['target']\n",
    "            elif('flash' in marker_stream[n]['time_series'][i][0]):\n",
    "                current_flash = json.loads(marker_stream[n]['time_series'][i][0])['flash']\n",
    "                onset.append(marker_stream[n]['time_stamps'][i] - eeg_stream[n]['time_stamps'][0])\n",
    "                duration.append(task_duration)\n",
    "                description.append(\"target\" if current_flash == current_target else \"nontarget\")\n",
    "    annotations = mne.Annotations(onset, duration, description)\n",
    "    eeg_raw = eeg_raw.set_annotations(annotations)\n",
    "    \n",
    "    # Create list of raw objects\n",
    "    eeg_raw_list.append(eeg_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce8688d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>19 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>16 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>62.50 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:14:05 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawArray | 16 x 105700 (845.6 s), ~12.9 MB, data loaded>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate raw objects\n",
    "raw = mne.concatenate_raws(eeg_raw_list)\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e81434",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91852a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "# Common average reference\n",
    "raw_orig = raw.copy()\n",
    "raw = raw.set_eeg_reference('average', projection=False)\n",
    "\n",
    "if plotGraphs:\n",
    "    fig = raw_orig.plot(title='Before Re-referencing', n_channels=16, scalings=scalings)\n",
    "    fig = raw.plot(title='After Re-referencing', n_channels=16, scalings=scalings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0930ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 5 contiguous segments\n",
      "Setting up band-pass filter from 0.1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 4125 samples (33.000 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bandpass filter data\n",
    "raw_orig = raw.copy()\n",
    "raw = raw.filter(l_freq=bp_l_freq, h_freq=bp_h_freq)\n",
    "\n",
    "if plotGraphs:\n",
    "    fig = raw_orig.plot(title='Before Filtering', scalings=scalings, duration=plot_duration)\n",
    "    fig = raw.plot(title='After Filtering', scalings=scalings, duration=plot_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b855a6",
   "metadata": {},
   "source": [
    "### ICA Artifact Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b190f69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 5 contiguous segments\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 413 samples (3.304 sec)\n",
      "\n",
      "Fitting ICA to data using 16 channels (please be patient, this may take a while)\n",
      "Selecting by number: 16 components\n",
      "Fitting ICA took 6.1s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leungj\\AppData\\Local\\Temp\\ipykernel_12320\\895341945.py:9: RuntimeWarning: Using n_components=16 (resulting in n_components_=16) may lead to an unstable mixing matrix estimation because the ratio between the largest (7.6) and smallest (2.7e-26) variances is too large (> 1e6); consider setting n_components=0.999999 or an integer <= 15\n",
      "  ica = ica.fit(raw_filt)\n"
     ]
    }
   ],
   "source": [
    "raw_orig = raw.copy()\n",
    "\n",
    "# filter data to remove slow drifts\n",
    "raw_filt = raw.copy()\n",
    "raw_filt.filter(l_freq=1., h_freq=None)\n",
    "\n",
    "# ICA decomposition\n",
    "ica = mne.preprocessing.ICA(n_components=16, method='fastica', max_iter=200, random_state=42, verbose=True)\n",
    "ica = ica.fit(raw_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1828eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ICA sources\n",
    "if plotGraphs:\n",
    "    fig = ica.plot_sources(raw_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb69e60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICA sources to exclude:  [0]\n"
     ]
    }
   ],
   "source": [
    "# Select source that corresponds to artifact and remove it\n",
    "ica.exclude = [0]\n",
    "# ica.exclude = [2]\n",
    "print('ICA sources to exclude: ', ica.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86f41cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (16 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 16 PCA components\n"
     ]
    }
   ],
   "source": [
    "ica.apply(raw)\n",
    "\n",
    "if plotGraphs:\n",
    "    fig = raw_orig.plot(title='Before ICA', scalings=scalings, duration=plot_duration)\n",
    "    fig = raw.plot(title='After ICA', scalings=scalings, duration=plot_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca8d881",
   "metadata": {},
   "source": [
    "### Epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5c88f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['MI/hands', 'rest']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 100 events and 626 original time points ...\n",
      "0 bad epochs dropped\n",
      "<Epochs |  100 events (all good), 0 - 5 sec, baseline off, ~7.7 MB, data loaded,\n",
      " 'MI/hands': 50\n",
      " 'rest': 50>\n"
     ]
    }
   ],
   "source": [
    "# Epoch data\n",
    "events, event_id = mne.events_from_annotations(raw, event_id=event_dict)\n",
    "epoch = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, picks='eeg', preload=True)\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e4a0e",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1db58950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFR freqs:  [ 6.          7.71912254  9.93080879 12.77618833 16.43682721 21.1463139\n",
      " 27.2051647  35.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "(100, 16, 8, 626)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  13 out of  16 | elapsed:    2.8s remaining:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done  16 out of  16 | elapsed:    2.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "y = epoch.events[:,-1] - min(epoch.events[:,-1])\n",
    "\n",
    "# Time-Domain Features\n",
    "if features == 'time':\n",
    "    scaler = Scaler(epoch.info)\n",
    "    X = scaler.fit_transform(epoch.get_data())\n",
    "    \n",
    "    if ('P300' in task) and plotGraphs:\n",
    "        evoked_target = epoch['target'].average()\n",
    "        fig = evoked_target.plot_joint(times=[0., 0.3, 0.4, 0.6, 0.7], picks=['C3', 'C4', 'P7', 'P3', 'P4', 'P8', 'O1', 'O2'])\n",
    "    \n",
    "# Frequency-Domain Features\n",
    "elif features == 'psd':\n",
    "    psds, freqs = psd_welch(epoch, average='mean', fmin=bp_l_freq, fmax=bp_h_freq, n_jobs=-1)\n",
    "    X = 10 * np.log10(psds)\n",
    "#     X = psds / np.sum(psds, axis=-1, keepdims=True)\n",
    "    \n",
    "    if ('MI' in task) and plotGraphs:\n",
    "        sel_chs = [2, 3, 4, 5, 6, 7, 14, 15]\n",
    "        psd_means_class_0 = np.transpose(np.mean(X[y==0], axis=0))\n",
    "        psd_means_class_1 = np.transpose(np.mean(X[y==1], axis=0))\n",
    "        psd_means_class_0 = psd_means_class_0[:,sel_chs]\n",
    "        psd_means_class_1 = psd_means_class_1[:,sel_chs]\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        for i in range(len(sel_chs)):\n",
    "            line = ax.plot(freqs, psd_means_class_0[:,i], ':', label=ch_names[sel_chs[i]] + ' Rest')\n",
    "            ax.plot(freqs, psd_means_class_1[:,i], '-', label=ch_names[sel_chs[i]] + ' MI-hands', color=line[0].get_color())\n",
    "        ax.set(title='Welch PSD', xlabel='Frequency (Hz)', ylabel='Power Spectral Density (dB)')\n",
    "        ax.set_ylim(bottom=-135, top=-85)\n",
    "        ax.legend(loc='best')\n",
    "\n",
    "# Time-frequency features\n",
    "elif features =='tfr':\n",
    "    # Parameters\n",
    "    freqs = np.logspace(*np.log10([6, 35]), num=8)\n",
    "#     freqs = np.linspace(2, 40, 20)\n",
    "    print('TFR freqs: ', freqs)\n",
    "    n_cycles = freqs / 2.\n",
    "    time_bandwidth = 4.0 # param for multitaper\n",
    "    \n",
    "    # Compute TFR Power\n",
    "    if tfr_type == 'morlet':\n",
    "        power = tfr_morlet(epoch, freqs, n_cycles=n_cycles, use_fft=False, return_itc=False, average=False, n_jobs=-1)\n",
    "    elif tfr_type == 'multitaper':\n",
    "        power = tfr_multitaper(epoch, freqs, n_cycles=n_cycles, time_bandwidth=time_bandwidth, use_fft=False, return_itc=False, average=False, n_jobs=-1)\n",
    "    print(power.data.shape)\n",
    "    X = power.data\n",
    "    \n",
    "    if ('MI' in task) and plotGraphs:\n",
    "        fig = power['rest'].average().plot_topo(baseline=baseline, mode='percent', cmap='jet', tmin=tmin, tmax=tmax, vmin=vmin, vmax=vmax, title='Average power (Rest)')\n",
    "        fig = power['MI/hands'].average().plot_topo(baseline=baseline, mode='percent', cmap='jet', tmin=tmin, tmax=tmax, vmin=vmin, vmax=vmax, title='Average power (MI-hands)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52e008cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # freqs = np.linspace(1, 40, 8)\n",
    "# freqs = np.logspace(*np.log10([6, 35]), num=8)\n",
    "# # freqs = np.array([1., 4., 8., 13., 30.])\n",
    "# print(freqs)\n",
    "# n_cycles = freqs / 2.  # different number of cycle per frequency\n",
    "\n",
    "# # Morlet\n",
    "# # freqs = np.logspace(*np.log10([6, 35]), num=8)\n",
    "# # n_cycles = freqs / 2.  # different number of cycle per frequency\n",
    "# power_rest, itc_rest = tfr_morlet(epoch['rest'], freqs, n_cycles=n_cycles, use_fft=False, return_itc=True, n_jobs=-1)\n",
    "# power_task, itc_task = tfr_morlet(epoch['MI/hands'], freqs, n_cycles=n_cycles, use_fft=False, return_itc=True, n_jobs=-1)\n",
    "\n",
    "# # # Multitaper\n",
    "# # freqs = np.logspace(*np.log10([6, 35]), num=8)\n",
    "# # n_cycles = freqs / 2.\n",
    "# # time_bandwidth = 4.0  # Same time-smoothing as (1), 7 tapers.\n",
    "# # power_rest = tfr_multitaper(epoch['rest'], freqs=freqs, n_cycles=n_cycles, time_bandwidth=time_bandwidth, return_itc=False)\n",
    "# # power_task = tfr_multitaper(epoch['MI/hands'], freqs=freqs, n_cycles=n_cycles, time_bandwidth=time_bandwidth, return_itc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ec34ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# baseline = (0., 0.1)\n",
    "# vmin, vmax = -1, 1\n",
    "# # if plotGraphs:\n",
    "# fig = power_rest.plot_topo(baseline=baseline, mode='percent', cmap='jet', tmin=0., tmax=tmax, vmin=vmin, vmax=vmax, title='Average power (Rest)')\n",
    "# fig = power_task.plot_topo(baseline=baseline, mode='percent', cmap='jet', tmin=0., tmax=tmax, vmin=vmin, vmax=vmax, title='Average power (MI-hands)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92b6ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select Channels\n",
    "# print('Selecting channels from data...')\n",
    "# print('Original X.shape: ', X.shape)\n",
    "# X = X[:,2:, :]\n",
    "# print('X.shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4adf9cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing features to 2D...\n",
      "Original X.shape:  (100, 16, 8, 626)\n",
      "X.shape:  (100, 80128)\n",
      "y.shape:  (100,)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize features\n",
    "if len(X.shape) > 2:\n",
    "    print('Vectorizing features to 2D...')\n",
    "    print('Original X.shape: ', X.shape)\n",
    "    vec = Vectorizer()\n",
    "    X = vec.fit_transform(X)\n",
    "\n",
    "print('X.shape: ', X.shape)\n",
    "print('y.shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59010a6",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4968dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "# Set up scoring\n",
    "scoring = 'accuracy'\n",
    "scores = {'Classifier': [],\n",
    "          'Score': [],\n",
    "          'Std': []\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47498dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Classifiers\n",
    "classifiers = []\n",
    "\n",
    "# KNN\n",
    "params = {}\n",
    "params['n_neighbors'] = np.arange(2,11,1)\n",
    "params['weights'] = ['uniform', 'distance']\n",
    "clf = HalvingGridSearchCV(KNeighborsClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['KNN', clf, params])\n",
    "\n",
    "# DT\n",
    "params = {}\n",
    "params['criterion'] = ['gini', 'entropy']\n",
    "params['min_samples_split'] = np.arange(2,11,2)\n",
    "clf = HalvingGridSearchCV(DecisionTreeClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['DT', clf, params])\n",
    "\n",
    "# RF\n",
    "params = {}\n",
    "params['criterion'] = ['gini', 'entropy']\n",
    "params['n_estimators'] = (10, 20, 30)\n",
    "params['min_samples_split'] = np.arange(2,11,2)\n",
    "clf = HalvingGridSearchCV(RandomForestClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['RF', clf, params])\n",
    "\n",
    "# LDA\n",
    "params = {}\n",
    "params['solver'] = ['svd']\n",
    "clf = HalvingGridSearchCV(LinearDiscriminantAnalysis(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['LDA', clf, params])\n",
    "\n",
    "# SVM\n",
    "params = {}\n",
    "params['C'] = (1e-4, 1e-2, 1)\n",
    "params['gamma'] = (1e-4, 1e-2, 1, 10)\n",
    "params['kernel'] = ['linear', 'rbf']\n",
    "clf = HalvingGridSearchCV(SVC(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['SVM', clf, params])\n",
    "\n",
    "# SGD\n",
    "params = {}\n",
    "params['loss'] = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "params['penalty'] = ['l2', 'l1', 'elasticnet']\n",
    "params['alpha'] = (1e-4, 1e-2, 1, 10)\n",
    "clf = HalvingGridSearchCV(SGDClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['SGD', clf, params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa4fdb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN...\n",
      "KNN score: 0.56\n",
      "KNN std  : 0.10\n",
      "\n",
      "Training DT...\n",
      "DT score: 0.54\n",
      "DT std  : 0.03\n",
      "\n",
      "Training RF...\n",
      "RF score: 0.54\n",
      "RF std  : 0.03\n",
      "\n",
      "Training LDA...\n",
      "LDA score: 0.55\n",
      "LDA std  : 0.11\n",
      "\n",
      "Training SVM...\n",
      "SVM score: 0.52\n",
      "SVM std  : 0.03\n",
      "\n",
      "Training SGD...\n",
      "SGD score: 0.51\n",
      "SGD std  : 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Classifiers\n",
    "for c in range(len(classifiers)):\n",
    "    clf_name = classifiers[c][0]\n",
    "    clf = classifiers[c][1].fit(X, y)\n",
    "    print(\"Training %s...\" % clf_name)\n",
    "    print('%s score: %2.2f' % (clf_name, clf.best_score_))\n",
    "    print('%s std  : %2.2f' % (clf_name, np.mean(clf.cv_results_['std_test_score'])))\n",
    "    print()\n",
    "    scores['Classifier'].append(clf_name)\n",
    "    scores['Score'].append(clf.best_score_)\n",
    "    scores['Std'].append(np.mean(clf.cv_results_['std_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6522303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.095329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.034641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.033452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.111283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.031775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Score       Std\n",
       "0        KNN  0.556  0.095329\n",
       "1         DT  0.540  0.034641\n",
       "2         RF  0.540  0.033452\n",
       "3        LDA  0.554  0.111283\n",
       "4        SVM  0.518  0.031775\n",
       "5        SGD  0.510  0.000735"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score summary\n",
    "df = pd.DataFrame(scores)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba6adb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Classifier:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier         KNN\n",
       "Score            0.556\n",
       "Std           0.095329\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Classifier\n",
    "print('Best Classifier:')\n",
    "df.loc[df['Score'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4d918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
