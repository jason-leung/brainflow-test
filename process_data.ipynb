{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0fcdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f04187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, pyxdf, json\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from mne.time_frequency import psd_welch\n",
    "from mne.decoding import Scaler, Vectorizer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, HalvingGridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0ee15",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd8160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "subject = 'P00J'\n",
    "session = 1\n",
    "# task = 'MI-hands'\n",
    "task = 'P300_4x4_gface'\n",
    "lslDir = os.path.join(os.path.expanduser('~'), 'Documents\\CurrentStudy')\n",
    "\n",
    "# LSL Stream\n",
    "eeg_stream_type = 'EXG'\n",
    "markers_stream_type = 'Marker'\n",
    "\n",
    "# Events\n",
    "if task == 'MI-hands':\n",
    "    event_dict = {'rest': 0, 'MI/hands': 1}\n",
    "    rest_duration = 5\n",
    "    task_duration = 5\n",
    "    tmin = 0\n",
    "    tmax = 5\n",
    "elif 'P300' in task:\n",
    "    event_dict = {'nontarget': 0, 'target': 1}\n",
    "    task_duration = 1\n",
    "    tmin = 0\n",
    "    tmax = 1\n",
    "\n",
    "# Plot\n",
    "plotGraphs = True\n",
    "scalings = dict(eeg=200e-6)\n",
    "plot_duration = 10\n",
    "\n",
    "# Bandpass filter\n",
    "bp_l_freq = 0.1\n",
    "bp_h_freq = 40.\n",
    "\n",
    "# Features\n",
    "features = 'time'\n",
    "# features = 'psd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e14168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sub-folder for data\n",
    "fif_dir = os.path.join('fif')\n",
    "if not os.path.exists(fif_dir):\n",
    "    os.makedirs(fif_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df62ee7",
   "metadata": {},
   "source": [
    "### Find LSL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93040a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-P00J_ses-S001_task-P300_4x4_gface_run-001_eeg.xdf\n",
      "sub-P00J_ses-S001_task-P300_4x4_gface_run-002_eeg.xdf\n",
      "sub-P00J_ses-S001_task-P300_4x4_gface_run-003_eeg.xdf\n",
      "sub-P00J_ses-S001_task-P300_4x4_gface_run-004_eeg.xdf\n",
      "sub-P00J_ses-S001_task-P300_4x4_gface_run-005_eeg.xdf\n"
     ]
    }
   ],
   "source": [
    "# Find files\n",
    "xdf_files = []\n",
    "hasSubject = subject!=''\n",
    "hasSession = session!=''\n",
    "hasTask = task!=''\n",
    "for root, dir, files in os.walk(lslDir):\n",
    "    for file in files:\n",
    "        validFile = True\n",
    "        if hasSubject:\n",
    "            validFile = validFile and (('sub-'+subject) in file)\n",
    "        if hasSession:\n",
    "            validFile = validFile and (('ses-S' + str(session).zfill(3)) in file)\n",
    "        if hasTask:\n",
    "            validFile = validFile and (('task-' + task) in file)\n",
    "        validFile = validFile and file.endswith('.xdf')\n",
    "        if validFile:\n",
    "            print(file)\n",
    "            matchingFile = os.path.join(root, file)\n",
    "            xdf_files.append(matchingFile)\n",
    "\n",
    "if len(xdf_files) == 0:\n",
    "    print('No files found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082bb234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing streams\n",
      "Found EXG stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-001_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-001_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-002_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-002_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-003_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-003_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-004_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-004_eeg.xdf\n",
      "Found EXG stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-005_eeg.xdf\n",
      "Found Marker stream in sub-P00J_ses-S001_task-P300_4x4_gface_run-005_eeg.xdf\n"
     ]
    }
   ],
   "source": [
    "# Parse streams\n",
    "eeg_stream, marker_stream = [], []\n",
    "\n",
    "print('Parsing streams')\n",
    "for xdf_file in xdf_files:\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)\n",
    "    for i in range(len(streams)):\n",
    "        if streams[i]['info']['type'][0] == eeg_stream_type:\n",
    "            print(\"Found %s stream in %s\" % (eeg_stream_type, os.path.basename(xdf_file)))\n",
    "            eeg_stream.append(streams[i])\n",
    "        elif streams[i]['info']['type'][0] == markers_stream_type:\n",
    "            print(\"Found %s stream in %s\" % (markers_stream_type, os.path.basename(xdf_file)))\n",
    "            marker_stream.append(streams[i])\n",
    "del streams, header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af60e1",
   "metadata": {},
   "source": [
    "### Extract EEG and Marker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569b6f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EEG info\n",
      "EEG channel names not found... setting default\n",
      "Channels:  ['FP1', 'FP2', 'C3', 'C4', 'P7', 'P8', 'O1', 'O2', 'F7', 'F8', 'F3', 'F4', 'T7', 'T8', 'P3', 'P4']\n",
      "Sampling frequency:  125.0\n"
     ]
    }
   ],
   "source": [
    "# Extract EEG Info\n",
    "print(\"Extracting EEG info\")\n",
    "\n",
    "ch_names = []\n",
    "if eeg_stream[0]['info']['desc'][0]:\n",
    "    print(\"EEG channel names found\")\n",
    "    for i in range(len(eeg_stream[0]['info']['desc'][0]['channels'][0]['channel'])):\n",
    "        ch_names.append(eeg_stream[0]['info']['desc'][0]['channels'][0]['channel'][i]['label'][0])\n",
    "else:\n",
    "    print(\"EEG channel names not found... setting default\")\n",
    "    ch_names = ['FP1', 'FP2', 'C3', 'C4', 'P7', 'P8', 'O1', 'O2', 'F7', 'F8', 'F3', 'F4', 'T7', 'T8', 'P3', 'P4']\n",
    "print('Channels: ', ch_names)\n",
    "\n",
    "sfreq = float(eeg_stream[0]['info']['nominal_srate'][0])\n",
    "print('Sampling frequency: ', sfreq)\n",
    "\n",
    "# Create MNE info object\n",
    "eeg_info = mne.create_info(ch_names, sfreq, ch_types='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f764ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Montage\n",
    "montage = mne.channels.read_custom_montage('openbci_montage.elc')\n",
    "# montage.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8048953f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 21304)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=21304\n",
      "    Range : 0 ... 21303 =      0.000 ...   170.424 secs\n",
      "Ready.\n",
      "(16, 21411)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=21411\n",
      "    Range : 0 ... 21410 =      0.000 ...   171.280 secs\n",
      "Ready.\n",
      "(16, 21048)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=21048\n",
      "    Range : 0 ... 21047 =      0.000 ...   168.376 secs\n",
      "Ready.\n",
      "(16, 20686)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=20686\n",
      "    Range : 0 ... 20685 =      0.000 ...   165.480 secs\n",
      "Ready.\n",
      "(16, 20309)\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=20309\n",
      "    Range : 0 ... 20308 =      0.000 ...   162.464 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# Get all EEG data\n",
    "eeg_raw_list = []\n",
    "\n",
    "for n in range(len(eeg_stream)):\n",
    "    # Create MNE Raw object\n",
    "    eeg_data = np.transpose(eeg_stream[n]['time_series'])\n",
    "    eeg_data = eeg_data / 1e6\n",
    "    print(eeg_data.shape)\n",
    "    eeg_raw = mne.io.RawArray(eeg_data, eeg_info)\n",
    "    \n",
    "#     # Set FP1 and FP2 as EOG channels\n",
    "#     eeg_raw = eeg_raw.set_channel_types({'FP1': 'eog', 'FP2': 'eog'})\n",
    "#     eeg_raw.pick_types(eeg=True, eog=True)\n",
    "    \n",
    "    # Set montage\n",
    "    eeg_raw = eeg_raw.set_montage(montage)\n",
    "\n",
    "    # Add annotations\n",
    "    onset, duration, description = [], [], []\n",
    "    current_target = -1\n",
    "    current_flash = -1\n",
    "    for i in range(len(marker_stream[n]['time_series'])):\n",
    "        if 'MI' in task:\n",
    "            if ('rest' in marker_stream[n]['time_series'][i][0]):\n",
    "                onset.append(marker_stream[n]['time_stamps'][i] - eeg_stream[n]['time_stamps'][0])\n",
    "                duration.append(rest_duration)\n",
    "                description.append(marker_stream[n]['time_series'][i][0])\n",
    "            elif ('task' in marker_stream[n]['time_series'][i][0]):\n",
    "                onset.append(marker_stream[n]['time_stamps'][i] - eeg_stream[n]['time_stamps'][0])\n",
    "                duration.append(task_duration)\n",
    "                description.append(marker_stream[n]['time_series'][i][0].replace('task_', '').replace('-','/'))\n",
    "        elif 'P300' in task:\n",
    "            if('target' in marker_stream[n]['time_series'][i][0]):\n",
    "                current_target = json.loads(marker_stream[n]['time_series'][i][0])['target']\n",
    "            elif('flash' in marker_stream[n]['time_series'][i][0]):\n",
    "                current_flash = json.loads(marker_stream[n]['time_series'][i][0])['flash']\n",
    "                onset.append(marker_stream[n]['time_stamps'][i] - eeg_stream[n]['time_stamps'][0])\n",
    "                duration.append(task_duration)\n",
    "                description.append(\"target\" if current_flash == current_target else \"nontarget\")\n",
    "    annotations = mne.Annotations(onset, duration, description)\n",
    "    eeg_raw = eeg_raw.set_annotations(annotations)\n",
    "    \n",
    "    # Create list of raw objects\n",
    "    eeg_raw_list.append(eeg_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce8688d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>19 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>16 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>62.50 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:13:58 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawArray | 16 x 104758 (838.1 s), ~12.8 MB, data loaded>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate raw objects\n",
    "raw = mne.concatenate_raws(eeg_raw_list)\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e81434",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91852a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Using matplotlib as 2D backend.\n"
     ]
    }
   ],
   "source": [
    "# Common average reference\n",
    "raw_orig = raw.copy()\n",
    "raw = raw.set_eeg_reference('average', projection=False)\n",
    "\n",
    "if plotGraphs:\n",
    "    fig = raw_orig.plot(title='Before Re-referencing', n_channels=16, scalings=scalings)\n",
    "    fig = raw.plot(title='After Re-referencing', n_channels=16, scalings=scalings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0930ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 5 contiguous segments\n",
      "Setting up band-pass filter from 0.1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 4125 samples (33.000 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bandpass filter data\n",
    "raw_orig = raw.copy()\n",
    "raw = raw.filter(l_freq=bp_l_freq, h_freq=bp_h_freq)\n",
    "\n",
    "if plotGraphs:\n",
    "    fig = raw_orig.plot(title='Before Filtering', scalings=scalings, duration=plot_duration)\n",
    "    fig = raw.plot(title='After Filtering', scalings=scalings, duration=plot_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b855a6",
   "metadata": {},
   "source": [
    "### ICA Artifact Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b190f69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 5 contiguous segments\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 413 samples (3.304 sec)\n",
      "\n",
      "Fitting ICA to data using 16 channels (please be patient, this may take a while)\n",
      "Selecting by number: 16 components\n",
      "Fitting ICA took 2.3s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\AppData\\Local\\Temp\\ipykernel_4636\\895341945.py:9: RuntimeWarning: Using n_components=16 (resulting in n_components_=16) may lead to an unstable mixing matrix estimation because the ratio between the largest (11) and smallest (5.7e-26) variances is too large (> 1e6); consider setting n_components=0.999999 or an integer <= 15\n",
      "  ica = ica.fit(raw_filt)\n"
     ]
    }
   ],
   "source": [
    "raw_orig = raw.copy()\n",
    "\n",
    "# filter data to remove slow drifts\n",
    "raw_filt = raw.copy()\n",
    "raw_filt.filter(l_freq=1., h_freq=None)\n",
    "\n",
    "# ICA decomposition\n",
    "ica = mne.preprocessing.ICA(n_components=16, method='fastica', max_iter=200, random_state=42, verbose=True)\n",
    "ica = ica.fit(raw_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1828eae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=16, n_times=104758\n",
      "    Range : 0 ... 104757 =      0.000 ...   838.056 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# Plot ICA sources\n",
    "fig = ica.plot_sources(raw_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb69e60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICA sources to exclude:  []\n"
     ]
    }
   ],
   "source": [
    "# Select source that corresponds to artifact and remove it\n",
    "# ica.exclude = [0]\n",
    "# ica.exclude = [2]\n",
    "print('ICA sources to exclude: ', ica.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86f41cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (16 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 16 PCA components\n"
     ]
    }
   ],
   "source": [
    "ica.apply(raw)\n",
    "\n",
    "if plotGraphs:\n",
    "    fig = raw_orig.plot(title='Before ICA', scalings=scalings, duration=plot_duration)\n",
    "    fig = raw.plot(title='After ICA', scalings=scalings, duration=plot_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca8d881",
   "metadata": {},
   "source": [
    "### Epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5c88f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['nontarget', 'target']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "4000 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 4000 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "<Epochs |  4000 events (all good), 0 - 1 sec, baseline off, ~61.6 MB, data loaded,\n",
      " 'nontarget': 3750\n",
      " 'target': 250>\n"
     ]
    }
   ],
   "source": [
    "# Epoch data\n",
    "events, event_id = mne.events_from_annotations(raw, event_id=event_dict)\n",
    "epoch = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, picks='eeg', preload=True)\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e4a0e",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "080f2901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No projector specified for this dataset. Please consider the method self.add_proj.\n"
     ]
    }
   ],
   "source": [
    "evoked_target = epoch['target'].average()\n",
    "fig = evoked_target.plot_joint(times=[0., 0.3, 0.4, 0.6, 0.7], picks=['C3', 'C4', 'P7', 'P3', 'P4', 'P8', 'O1', 'O2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db58950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Labels\n",
    "y = epoch.events[:,-1] - min(epoch.events[:,-1])\n",
    "\n",
    "# Time-Domain Features\n",
    "if features == 'time':\n",
    "    scaler = Scaler(epoch.info)\n",
    "    X = scaler.fit_transform(epoch.get_data())\n",
    "    \n",
    "#     if ('P300' in task) and plotGraphs:\n",
    "#         evoked_target = eeg_epoch['target'].average()\n",
    "#         evoked_target.plot()\n",
    "    \n",
    "# Frequency-Domain Features\n",
    "elif features == 'psd':\n",
    "    psds, freqs = psd_welch(epoch, average='mean', fmin=bp_l_freq, fmax=bp_h_freq, n_jobs=-1)\n",
    "    X = 10 * np.log10(psds)\n",
    "#     X = psds / np.sum(psds, axis=-1, keepdims=True)\n",
    "    \n",
    "    if ('MI' in task) and plotGraphs:\n",
    "        sel_chs = [2, 3, 4, 5, 6, 7, 14, 15]\n",
    "        psd_means_class_0 = np.transpose(np.mean(X[y==0], axis=0))\n",
    "        psd_means_class_1 = np.transpose(np.mean(X[y==1], axis=0))\n",
    "        psd_means_class_0 = psd_means_class_0[:,sel_chs]\n",
    "        psd_means_class_1 = psd_means_class_1[:,sel_chs]\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        for i in range(len(sel_chs)):\n",
    "            line = ax.plot(freqs, psd_means_class_0[:,i], ':', label=ch_names[sel_chs[i]] + ' Rest')\n",
    "            ax.plot(freqs, psd_means_class_1[:,i], '-', label=ch_names[sel_chs[i]] + ' MI-hands', color=line[0].get_color())\n",
    "        ax.set(title='Welch PSD', xlabel='Frequency (Hz)', ylabel='Power Spectral Density (dB)')\n",
    "        ax.set_ylim(bottom=-135, top=-85)\n",
    "        ax.legend(loc='best')\n",
    "\n",
    "# Vectorize features\n",
    "if len(X.shape) > 2:\n",
    "    print('Vectorizing features to 2D...')\n",
    "    print('Original X.shape: ', X.shape)\n",
    "    vec = Vectorizer()\n",
    "    X = vec.fit_transform(X)\n",
    "\n",
    "print('X.shape: ', X.shape)\n",
    "print('y.shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59010a6",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "# Set up scoring\n",
    "scoring = 'accuracy'\n",
    "scores = {'Classifier': [],\n",
    "          'Score': [],\n",
    "          'Std': []\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47498dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Classifiers\n",
    "classifiers = []\n",
    "\n",
    "# KNN\n",
    "params = {}\n",
    "params['n_neighbors'] = np.arange(2,11,1)\n",
    "params['weights'] = ['uniform', 'distance']\n",
    "clf = HalvingGridSearchCV(KNeighborsClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['KNN', clf, params])\n",
    "\n",
    "# DT\n",
    "params = {}\n",
    "params['criterion'] = ['gini', 'entropy']\n",
    "params['min_samples_split'] = np.arange(2,11,2)\n",
    "clf = HalvingGridSearchCV(DecisionTreeClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['DT', clf, params])\n",
    "\n",
    "# RF\n",
    "params = {}\n",
    "params['criterion'] = ['gini', 'entropy']\n",
    "params['n_estimators'] = (10, 20, 30)\n",
    "params['min_samples_split'] = np.arange(2,11,2)\n",
    "clf = HalvingGridSearchCV(RandomForestClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['RF', clf, params])\n",
    "\n",
    "# LDA\n",
    "params = {}\n",
    "params['solver'] = ['svd']\n",
    "clf = HalvingGridSearchCV(LinearDiscriminantAnalysis(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['LDA', clf, params])\n",
    "\n",
    "# SVM\n",
    "params = {}\n",
    "params['C'] = (1e-4, 1e-2, 1)\n",
    "params['gamma'] = (1e-4, 1e-2, 1, 10)\n",
    "params['kernel'] = ['linear', 'rbf']\n",
    "clf = HalvingGridSearchCV(SVC(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['SVM', clf, params])\n",
    "\n",
    "# SGD\n",
    "params = {}\n",
    "params['loss'] = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "params['penalty'] = ['l2', 'l1', 'elasticnet']\n",
    "params['alpha'] = (1e-4, 1e-2, 1, 10)\n",
    "clf = HalvingGridSearchCV(SGDClassifier(), param_grid=params, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "classifiers.append(['SGD', clf, params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fdb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Classifiers\n",
    "for c in range(len(classifiers)):\n",
    "    clf_name = classifiers[c][0]\n",
    "    clf = classifiers[c][1].fit(X, y)\n",
    "    print(\"Training %s...\" % clf_name)\n",
    "    print('%s score: %2.2f' % (clf_name, clf.best_score_))\n",
    "    print('%s std  : %2.2f' % (clf_name, np.mean(clf.cv_results_['std_test_score'])))\n",
    "    print()\n",
    "    scores['Classifier'].append(clf_name)\n",
    "    scores['Score'].append(clf.best_score_)\n",
    "    scores['Std'].append(np.mean(clf.cv_results_['std_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6522303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score summary\n",
    "df = pd.DataFrame(scores)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6adb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Classifier\n",
    "print('Best Classifier:')\n",
    "df.loc[df['Score'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4d918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
